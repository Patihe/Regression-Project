lapply(x, sum)
lapply(x, min)
x <- list(a=matrix(1:4,2,2)),matrix(1:6,3,2)
x <- list(a=matrix(1:4,2,2)),matrix(1:6,3,2))
x <- list(a=matrix(1:4,2,2)),b=matrix(1:6,3,2))
x <- list(a=matrix (1:4,2,2)), b=matrix (1:6,3,2))
x <- list (a=matrix (1:4,2,2), b=matrix (1:6,3,2))
lapply(x, function (x) x[,1]/2)
x <-list (a=1:5, b=6:10)
lapply(x, mean)
sapply(x, mean)
names<-c ("ting", "ting", "chong", "chong", "chong")
subject<-c ("IT", "CS", "AI", "CS", "AI")
marks<-c (90, 95, 80, 90, 99, 85)
dt<-data.frame(name, subject, marks)
dt<-data.frame('name', subject, marks)
dt<-data.frame(name,subject,marks)
dt<-data.frame (name,subject,marks)
split(dt, dt$name)
split(dt, dt$name)
x <- rnorm(1000)
summary(x)
x <- dnorm(1000)
summary(x)
x <- pnorm(1000)
summary(x)
x <- rpois(1000)
x <- Rpois(1000)
x <- rpois(1000)
set.seed(10)
10
sample (10)
sample (10)
sample (10)
sample (10)
sample (10)
set.seed(1)
sample (10)
sample (10)
sample (10)
set.seed(1)
sample (10)
set.seed(2)
x <- rep (0:2, each = 3)
e <- rnorm(9, 0, 20) # Generate 9 random numbers
y <- 0.5 + 2 * x + e
sample (2)
library (datasets)
Rprof()
fit <- lm(y ~ x + e)
Rprof(NULL)
summaryRprof()
}
setwd("~/")
## Example of Lexical Scoping
x <- "vegas"
x
numeric_vector <- c(1, 10, 49)
character_vector <- c("a","b","c")
boolean_vector <- c(TRUE, FALSE, TRUE)
49
b
c()
x <- c(4, "a", TRUE)
x
x <- c(1,3, 5)
y <- c(3, 2, 10)
rbind(x, y)
cbind(x, y)
x <- c(3, 5, 1, 10, 12, 6)
x
x <- c(17, 14, 4, 5, 13, 12, 10)
x
x[x > 10] == 4
x[x > 4] <- 10
x
x <- list(2, "a", "b", TRUE)
x[[1]]
install.packages("swirl")
library(swirl)
install_from_swirl("R Programming")
swirl()
5 + 7
x <- 5 + 7
x
y <- 3
y <- x - 3
y
c(1.1, 9, 3.14)
z <- c(1.1, 9, 3.14)
?c
z
z <- c(z, 555)
c(z, 555, z)
z * 2 + 100
z - 1
sqrt(z - 1)
info ()
sqrt ("my_sqrt")
()
sqrt (z -1)
nxt()
z <- 1("my_sqrt")
my_sqrt <- sqrt(z - 1)
my_sqrt
my_div <- sqrt(z / my_sqrt)
my_div <- z / my_sqrt
my_div
c(1, 2, 3, 4) + c(0, 10)
c(1, 2, 3, 4) + c(0, 10, 100)
z * 2 + 1000
my_div
x <- as.Date("1973-04-06")
x
f <- function(x) {
g <- function(y) {
y + z
}
z <- 4
x + g(x)
}
z <- 10
f(3)
x <- 5
y <- if(x < 3) {
NA
} else {
10
}
y
h <- function(x, y = NULL, d = 3L) {
z <- cbind(x, d)
if(!is.null(y))
z <- z + y
else
z <- z + f
g <- x + y / z
if(d == 3L)
return(g)
g <- g + 10
g
}
z
f
x
g
d
l
library(datasets)
data(iris)
?iris
iris
library(datasets)
data(mtcars)
?mtcars
sapply(mtcars, cyl, mean)
with(mtcars, tapply(mpg, cyl, mean))
lapply(mtcars, mean)
apply(mtcars, 2, mean)
mean(mtcars[mtcars$cyl == "8",]$hp) - mean(mtcars[mtcars$cyl == "4",]$hp)
library(swirl)
swirl()
num_vect <- c(0.5, 55, -10, 6)
tf <- num_vect < 1
tf
num_vect >= 6
my_char <- c("My", "name", "is")
my_char
paste(my_char, collapse = " ")
my_name <- c(my_char, "Pat")
my_name
paste(my_name, collapse = " ")
paste("Hello", "world!", sep = " ")
paste(1:3, c("X", "Y", "Z"), sep = "")
paste(LETTERS, 1:4, sep = "-")
x <- c(44, NA, 5, NA)
x * 3
y <- rnorm(1000)
z <- rep(NA, 1000)
my_data <- sample(c(y, z), 100)
my_na <- is.na(my_data)
my_na
my_data == NA
sum(my_na)
my_data
0/0
Inf - Inf
libary(swirl)
swirl()
library(swirl)
swirl()
skip()
skip()
skip()
skip()
skip()
skip()
my_sqrt
skip()
skip()
skip()
skip()
skip()
skip()
library(datasets) hist(warpbreaks$breaks, breaks=20, xlab = "Breaks", main="Number Breaks in Yarn during Weaving", ylim = c(0,20)
library(datasets)
ls
library(datasets) hist(warpbreaks$breaks, breaks=20, xlab = "Breaks", main="Number Breaks in Yarn during Weaving", ylim = c(0,20))
library("MASS") data("cats") plot(cats$Bwt, cats$Hwt, type="l", col="red", lwd=1, ylab="Heart weight (Kg)", xlab="Body weight (Kg)", main="Anatomical features of house cats") fit1<-lm(formula= cats$Hwt ~ cats$Bwt) abline(fit1, lty="dashed") #sample of text to be placed in plot text(x=2.3, y=18, labels="R2=0.896\n P=2615e-15")
library(datasets) hist(warpbreaks$breaks, breaks=20, xlab = "Breaks", main="Number Breaks in Yarn during Weaving", ylim = c(0,20))
library("MASS")
data("cats")
plot(cats$Bwt, cats$Hwt,
type="l",
col="red",
lwd=1,
ylab="Heart weight (Kg)",
xlab="Body weight (Kg)",
main="Anatomical features of house cats")
fit1<-lm(formula= cats$Hwt~ cats$Bwt)
abline(fit1, lty="dashed")
#sample of text to be placed in plot
text(x=2.3, y=18, labels="R2=0.896\n P=2615e-15")
library(lattice)
library(datasets)
#boxplotSepal.Lengthby Species
bwplot(Sepal.Length~ factor(Species) , data=iris,
xlab="Species",
col="red",
pch=16,
main=("Sepal.Lengthby Species"))
R.version.string
library(swirl)
install_from_swirl("Getting and Cleaning Data")
library(swirl)
swirl()
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
-5:20
-(5:20)
select(cran, -(X:size))
filter(cran, package == "swirl")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3, 5, NA, 10))
"!is.na(c(3, 5, NA, 10))"
!is.na(c(3, 5, NA, 10))
filter(cran, !is.na(r_version))
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size = size + 1000)
summarize(cran, avg_bytes = mean(size))
library(dplyr)
cran <- tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package <- group_by(cran, package)
by_package
summarize(by_package, mean(size))
submit()
reset()
script_results_identical('pack_sum'); multi_expr_creates_var('pack_sum')
skip()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts <- filter(pack_sum, count > 679)
top_counts
top_counts
View(top_counts)
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique > 465)
View(top_unique)
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
script_results_identical('result1'); multi_expr_creates_var('result1')
View(result3)
skip()
View(result3)
script_results_identical('result3'); multi_expr_creates_var('result3')
skip()
submit()
View(result3)
cran %>%
select() %>%
print
skip()
script_vals_identical()
skip()
skip()
arrange()
skip()
histogram(~disp| factor(cyl), data=mtcars,
main="Displacement by Cylinders",
xlab="Displacment(cu in)",
col="blue")
load("D:/Data Scientist/Exploratory Data Analysis/.RData")
library(datasets)
plot(iris$Sepal.Length, iris$Petal.Length,
col=iris$Species,
pch=16,
cex=0.5,
xlab="Sepal Length",
ylab="Petal Length",
main="Flower Characteristics in Iris")
legend(x=4.2, y=7, legend=levels(iris$Species),col=c(1:3), pch=16)
```
library (swirl)
install_from_swirl("Statistical Inference")
swirl()
11/12
deck
52
4/52
0
3/13
2/51
.64
.64
mypdf
integrate(mypdf,0,1.6)
1.414214
.997*.001
(1-.985)*(1-.001)
.000997/(.000997+.014985)
3.5
expect_dice
dice_high
expect_dice(dice_high)
expect_dice(dice_low)
3.5
integrate(myfunc,0,2)
spop
mean(spop)
allsam
apply(allsam,1,mean)
mean(smeans)
dice_sqr
ex2_fair <- sum(dice_fair * dice_sqr)
ex2_fair-3.5^2
sum(dice_high * dice_sqr)-edh^2
omnitest(correctExpr='sd(apply(matrix(rnorm(10000),1000),1,mean))')
sd(apply(matrix(rnorm(10000),1000),1,mean))
1/sqrt(10)
1/sqrt(120)
sd(apply(matrix(runif(10000),1000),1,mean))
2/sqrt(10)
sd(apply(matrix(rpois(10000,4),1000),1,mean))
1/(2*sqrt(10))
sd(apply(matrix(sample(0:1,10000,TRUE),1000),1,mean))
0.94208
pbinom(2,size=5,prob=.8,lower.tail=FALSE)
qnorm(.10)
0
qnorm(.975,mean=3,sd=2)
6.92
pnorm(1200,mean=1020,sd=50,lower.tail=FALSE)
pnorm((1200-1020)/50,lower.tail=FALSE)
qnorm(.75,mean=1020,sd=50)
.53
.53
ppois(3,2.5 * 4)
pbinom(5,1000,.01)
ppois(5,1000*.01)
n=10
coinPlot(10)
coinPlot(10000)
qnorm(.95)
omnitest(correctExpr='.6 + c(-1,1)*qnorm(.975)*sqrt(.6*.4/100)')
.6 + c(-1,1)*qnorm(.975)*sqrt(.6*.4/100)
binom.test(60,100)$conf.int
mywald(.2)
ACCompar
ACCompar(20)
lamb <- 5/94.32
lamb +c(-1,1)*qnorm(.975)*sqrt(lamb/94.32)
poisson.test(5,94.32)$conf
myplot
myplot(2)
myplot(20)
myplot2(2)
qt(.975,2)
myplot2(20)
sleep
range(g1)
range(g2)
difference <- g2-g1
mean(difference)
s <- sd(difference)
mn + c(-1,1)*qt(.975,9)*s/sqrt(10)
t.test(difference)$conf.int
sp <- 7*15.34^2 + 20*18.23^2
ns <- 8+21-2
sp <- sqrt(sp/ns)
132.86-127.44+c(-1,1)*qt(.975,ns)*sp*sqrt(1/8+1/21)
sp <- sqrt((9*var(g1)+9*var(g2))/18)
md + c(-1,1)*qt(.975,18)*sp*sqrt(1/5)
t.test(g2,g1,paired=FALSE,var.equal=TRUE)$conf
t.test(g2,g1,paired=TRUE)$conf
num <- (15.34^2/8 + 18.23^2/21)^2
den <- 15.34^4/8^2/7 + 18.23^4/21^2/20
mydf <- num/den
132.86-127.44 +c(-1,1)*qt(.975,mydf)*sqrt(15.34^2/8 + 18.23^2/21)
1
2
.8
15
qt(.95,15)
dim(fs)
t.test(fs$sheight-fs$fheight)
11.7885 * sd(fs$sheight-fs$fheight)/sqrt(1078)
mybin
8
pt(2.5, 15, lower.tail=FALSE)
qnorm(.95)
qnorm(.99)
pnorm(2)
pnorm(2,lower.tail=FALSE)
mybin
pbinom(6,size=8,prob=.5,lower.tail=FALSE)
pbinom(7,size=8,prob=.5,lower.tail=TRUE)
ppois(9,5,lower.tail=FALSE)
myplot(34)
myplot(33.3)
myplot(30)
myplot(28)
z <- qnorm(.95)
pnorm(30+z,mean=30,lower.tail=FALSE)
pnorm(30+z,mean=32,lower.tail=FALSE)
pnorm(30+z,mean=32,sd=1,lower.tail=FALSE)
pnorm(30+z*2,mean=32,sd=2,lower.tail=FALSE)
power.t.test(n = 16, delta = 2 / 4, sd=1, type = "one.sample",  alt = "one.sided")$power
power.t.test(n = 16, delta = 2 , sd=4, type = "one.sample",  alt = "one.sided")$power
power.t.test(n = 16, delta = 100 , sd=200, type = "one.sample",  alt = "one.sided")$power
power.t.test(power = .8, delta = 2 / 4, sd=1, type = "one.sample",  alt = "one.sided")$n
power.t.test(power = .8, delta = 2, sd=4, type = "one.sample",  alt = "one.sided")$n
power.t.test(power = .8, delta = 100 , sd=200, type = "one.sample",  alt = "one.sided")$n
power.t.test(power = .8, n=26, sd=1, type = "one.sample",  alt = "one.sided")$delta
power.t.test(power = .8, n=27, sd=1, type = "one.sample",  alt = "one.sided")$delta
head(pValues)
sum(pValues < 0.05)
sum(p.adjust(pValues,method="bonferroni") < 0.05)
sum(p.adjust(pValues,method="BH") < 0.05)
tail(trueStatus)
table(pValues2 < 0.05, trueStatus)
24/500
"table(p.adjust(pValues2,method=\"bonferroni\") < 0.05, trueStatus)"
"table(p.adjust(pValues2,method=\"BH\") < 0.05, trueStatus)"
table(p.adjust(pValues2,method="bonferroni") < 0.05, trueStatus)
p.adjust
table(p.adjust(pValues2,method="BH") < 0.05, trueStatus)
3.5
print(g2)
head(sh)
nh
median(resampledMedians)
median(sh)
sam <- sample(fh,nh*B,replace=TRUE)
resam <- matrix(sam,B,nh)
meds <- apply(resam,1,median)
median(meds)-median(fh)
sd(meds)
sd(resampledMedians)
quantile(resampledMedians,c(.025,.975))
quantile(meds,c(.025,.975))
dim(InsectSprays)
names(InsectSprays)
range(Bdata$count)
range(Cdata$count)
BCcounts
group
testStat
obs <- testStat(BCcounts,group)
obs
mean(Bdata$count)-mean(Cdata$count)
sample(group)
"perms <- sapply(1 : 10000, function(i) testStat(BCcounts, sample(group)))"
mean(perms>obs)
mean(perms>obs)
perms <- sapply(1 : 10000, function(i) testStat(BCcounts,
| sample(group)))
perms <- sapply(1 : 10000, function(i) testStat(BCcounts, sample(group)))
mean(perms>obs)
testStat(DEcounts,group)
perms <- sapply(1 : 10000, function(i) testStat(DEcounts, sample(group)))
setwd("D:\\Data Scientist\\Regression models\\Regression Project")
In this project we are to analyze the Motor Trend magazine in exploring the relationship between a set of variables and miles per gallon (MPG) outcome. We will analyze the mtcars dataset from the 1974 Motor Trend US magazine and they are interested in the following two questions:
